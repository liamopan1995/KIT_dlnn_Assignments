{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### This submission is for... (*put up to three people*)\n",
        "- Erika Mustermann (87654321)\n",
        "- Max Mustermann (12345678)\n",
        "- Maxine Musterfrau (87651234)"
      ],
      "metadata": {
        "cell_id": "e6929dd6290a45bbbeba2dbd64adda8b",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 153.171875,
        "id": "BElyJk8jIFQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2A - Transformers"
      ],
      "metadata": {
        "cell_id": "9339153b4e8f400894090f4cdec8212f",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 82,
        "id": "fI0pnsRgIFRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you'll implement a basic encoder-only Transformer architecture with PyTorch. We will start with building the basic building blocks and then integrate them into a fully-fleged Transformer model. We train the model to solve a POS-Tagging problem (more on that later). In the previous exercise, you implemented your work in numpy. Now, we will switch to PyTorch, which will track the gradients for us and allows us to focus more on the network itself."
      ],
      "metadata": {
        "formattedRanges": [],
        "cell_id": "eef422cc65524297ab7b1220162873b0",
        "tags": [],
        "is_collapsed": false,
        "owner_user_id": "175a6e67-5f66-4c81-960a-2a75fbd3d9af",
        "deepnote_cell_type": "text-cell-p",
        "id": "8Mr3nD9SIFRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can receive up to three points for your implementation of Exercise 2A. Together with Exercise 1, you can get up to six bonus points for the exam."
      ],
      "metadata": {
        "cell_id": "64bcb0b3c2bb43a6b1620d47ecea1de6",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 74.78125,
        "id": "kFK2XQlGIFRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important Notice**: Throughout the notebook, basic structures are provided such as functions and classes without bodies or partial bodies, and variables that you need to assign to. **Don't change the names of functions, variables, and classes - and make sure that you are using them!** You're allowed to introduce helper variables and functions. Occasionally, we use **type annotations** that you should follow. They are not enforced by Python. Whenenver you see an ellipsis `...` you're supposed to insert code."
      ],
      "metadata": {
        "cell_id": "c66a0519697243859f4aa30b0a0e06c0",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 119.5625,
        "id": "LesSaHXNIFRC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "1ed55a8f3a8d4f8ea7f58929e119f5ed",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "aef22c3f",
        "execution_start": 1657123526340,
        "execution_millis": 40884,
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 696,
        "id": "ILTeXritIFRD",
        "outputId": "0f78ec82-1484-4dfd-c748-387d8f4a398a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torchtext torchdata torchmetrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.9/dist-packages (0.15.1)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.9/dist-packages (0.6.0)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.0.0+cu118)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata) (1.26.15)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (3.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchtext) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "20b2dbfb9550468d85d409a5a67f64c0",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2c538688",
        "execution_start": 1657123567236,
        "execution_millis": 810,
        "owner_user_id": "06b28ca6-80fe-4ecd-a509-50438de77bba",
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 149.375,
        "id": "h2xmf20nIFRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12719f24-23f4-48f9-ab46-27939641313c"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, Tensor\n",
        "from torch.nn.modules.dropout import Dropout\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" \n",
        "    print(\"Cuda is available\")\n",
        "else: \n",
        "  device = \"cpu\"\n",
        "  print(\"CUDA is not available. Execution time on the cpu is slow.\")\n",
        "\n",
        "  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available. Execution time on the cpu is slow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's actually start with a few basic functions that we will need throughout the exercise, namely **Softmax** and **ReLu**.\n",
        "\n",
        "$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n",
        "\n",
        "$\\text{ReLU}(x) = \\max(0, x)$"
      ],
      "metadata": {
        "cell_id": "925794d055334d71a1874bd0928f2358",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 131.1875,
        "id": "s8pKh0ZEIFRF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "89cb4d8c8ca04395a96eb2deedea1989",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 133,
        "id": "gMIKiWHcIFRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5dbac0b-31a0-4ee8-d0bd-0dce8f5a6332"
      },
      "source": [
        "def softmax(input: Tensor) -> Tensor:\n",
        "    offset,_ = input.max(axis=1,keepdims=True)\n",
        "    p = torch.exp(input - offset)\n",
        "    p /= torch.sum(p,axis=1)\n",
        "    return p \n",
        "\n",
        "\n",
        "def relu(input: Tensor) -> Tensor:\n",
        "    \n",
        "    return torch.maximum(input,torch.tensor(0))\n",
        "\n",
        "\n",
        "# Test\n",
        "\n",
        "# Softmax\n",
        "input = torch.linspace(0,16,steps = 16).reshape(4,4)\n",
        "print(input)\n",
        "\n",
        "print(softmax(input))\n",
        "\n",
        "print(softmax(input).sum(axis=1))\n",
        "\n",
        "# Relu\n",
        "input[:,1]= -1\n",
        "print(input)\n",
        "print(relu(input))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  1.0667,  2.1333,  3.2000],\n",
            "        [ 4.2667,  5.3333,  6.4000,  7.4667],\n",
            "        [ 8.5333,  9.6000, 10.6667, 11.7333],\n",
            "        [12.8000, 13.8667, 14.9333, 16.0000]])\n",
            "tensor([[0.0271, 0.0788, 0.2289, 0.6652],\n",
            "        [0.0271, 0.0788, 0.2289, 0.6652],\n",
            "        [0.0271, 0.0788, 0.2289, 0.6652],\n",
            "        [0.0271, 0.0788, 0.2289, 0.6652]])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000])\n",
            "tensor([[ 0.0000, -1.0000,  2.1333,  3.2000],\n",
            "        [ 4.2667, -1.0000,  6.4000,  7.4667],\n",
            "        [ 8.5333, -1.0000, 10.6667, 11.7333],\n",
            "        [12.8000, -1.0000, 14.9333, 16.0000]])\n",
            "tensor([[ 0.0000,  0.0000,  2.1333,  3.2000],\n",
            "        [ 4.2667,  0.0000,  6.4000,  7.4667],\n",
            "        [ 8.5333,  0.0000, 10.6667, 11.7333],\n",
            "        [12.8000,  0.0000, 14.9333, 16.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Block"
      ],
      "metadata": {
        "cell_id": "65d60a38ea0d41ca934e8a0f782b1672",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 70,
        "id": "SQnjC3EEIFRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A typical transformer block consists of the following \n",
        "- Multi-Head Attention\n",
        "- Layer Normalization\n",
        "- Linear Layer\n",
        "- Residual Connections"
      ],
      "metadata": {
        "cell_id": "090be921347b4f65a3dd0fca98b29c54",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 178.953125,
        "id": "zOFNjstIIFRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://i.imgur.com/ZKgcoe4.png\" alt=\"transformer block visualization\" width=\"200\">"
      ],
      "metadata": {
        "cell_id": "f87bf87fea1a44bcbc2d5c044843e007",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 353,
        "id": "8cQSCSZYIFRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next few subsections, we will build these basic building blocks."
      ],
      "metadata": {
        "formattedRanges": [],
        "cell_id": "1c8bd5f72db0415bbca4cdd48b0ecd52",
        "tags": [],
        "is_collapsed": false,
        "deepnote_cell_type": "text-cell-p",
        "id": "KH-g7DbCIFRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Head Attention"
      ],
      "metadata": {
        "cell_id": "59b1b38243a84b5c9571ddb814cd1a49",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 62,
        "id": "IBEZ5aQlIFRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Head Attention concatenates the outputs of several so called **attention heads**.\n",
        "\n",
        "$\\textrm{MHA}(Q,K,V) = \\textrm{Concat}(H_1,...,H_h)$"
      ],
      "metadata": {
        "cell_id": "a2a24844affe40a89f26ef6ca0346276",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 88.78125,
        "id": "e4lkJghYIFRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=300>"
      ],
      "metadata": {
        "cell_id": "ef2e9b876ee44b69a993f15856b206e9",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 376.15625,
        "id": "yr0td-vIIFRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One attention head consists of linear projections for each of $Q, K$ and $V$ and an attention mechanism called **Scaled Dot-Product Attention**. The attention mechanism scales down the dot products by $\\sqrt{d_k}$.\n",
        "\n",
        "$\\textrm{Attention}(Q,K,V)=\\textrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$\n",
        "\n",
        "\n",
        "\n",
        "If we assume that $q$ and $v$ are $d_k$-dimensional vectors and its components are independent random variables with mean $0$ and a variance of $d_k$, then their dot product has a mean of $0$ and variance of $d_k$. It is preferred to have a variance of $1$ and that's why we scale them down by $\\sqrt{d_k}$.\n",
        "\n",
        "The dot product $q \\cdot v$ resembles a measure of similarity.\n"
      ],
      "metadata": {
        "cell_id": "a045d2caec3e4020a7bb3fee5680442b",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 233.90625,
        "id": "gqllZw7dIFRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"350\">"
      ],
      "metadata": {
        "cell_id": "9495e574d00e4d3798368384c6b3825b",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 421.609375,
        "id": "kRnYFFGzIFRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start implementing these components. Note that our classes inherit from PyTorch's `nn.Module`. These modules allow us to hold our parameters and easily move them to the GPU (with `.to(...)`). It also let's us define the computation that is performed at every call, in the `forward()` method. For example, when we have an `Attention` module, initialize it like `attention = Attention(...)`, we are able to call it with `attention(Q, K, V)` (it'll execute the `forward` function in an optimized way)."
      ],
      "metadata": {
        "cell_id": "e3ed8097791f458a85f3aabfd0756d28",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 119.5625,
        "id": "to1Ondo6IFRI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "2fc20cdd2c4c4e95aa1cb044b1258d63",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 187,
        "id": "QZ74ZH9SIFRI"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_n:int):\n",
        "        super().__init__()\n",
        "        self.hidden_n = hidden_n\n",
        "        ...\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "4ad1acddce234ba98f163b58e34c04d1",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 241,
        "id": "Cl3Vtn5iIFRI"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    hidden_n: hidden dimension\n",
        "    h: number of heads\n",
        "\n",
        "    Usage:\n",
        "      attn = MultiHeadAttention(hidden_n, h=2)\n",
        "      # self-attention\n",
        "      data = torch.randn(batch_size, sequence_length, hidden_n)\n",
        "      self_attn_output = attn(query=data, key=data, value=data)\n",
        "      # attention using two inputs\n",
        "      other_data = torch.randn(batch_size, sequence_length, hidden_n)\n",
        "      attn_output = attn(query=data, key=other_data, value=other_data)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_n:int, h:int = 2, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Construct a new MultiHeadAttention layer.\n",
        "        Inputs:\n",
        "         - hidden_n: Dimension of the token embedding\n",
        "         - h: Number of attention heads\n",
        "         - dropout: Dropout probability\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert hidden_n % h == 0\n",
        "\n",
        "        self.key = nn.Linear(hidden_n, hidden_n)\n",
        "        self.query = nn.Linear(hidden_n, hidden_n)\n",
        "        self.value = nn.Linear(hidden_n, hidden_n)\n",
        "        self.proj = nn.Linear(hidden_n, hidden_n)\n",
        "\n",
        "        self.h = h\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.scale = math.sqrt(hidden_n / h)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask=None):\n",
        "        \"\"\"\n",
        "        Calculate the masked attention output for the provided data, computing\n",
        "        all attention heads in parallel.\n",
        "        In the shape definitions below, N is the batch size, S is the source\n",
        "        sequence length, T is the target sequence length, and E is the embedding(hidden_dimension)\n",
        "        dimension.\n",
        "        Inputs:\n",
        "        - query: Input data to be used as the query, of shape (N, S, E)\n",
        "        - key: Input data to be used as the key, of shape (N, T, E)\n",
        "        - value: Input data to be used as the value, of shape (N, T, E)\n",
        "        - attn_mask: Array of shape (T, S) where mask[i,j] == 0 indicates token\n",
        "          i in the target should not be influenced by token j in the source.\n",
        "        Returns:\n",
        "        - output: Tensor of shape (N, S, E) giving the weighted combination of\n",
        "          data in value according to the attention weights calculated using key\n",
        "          and query.\n",
        "        \"\"\"\n",
        "        N, S, D = query.shape\n",
        "        N, T, D = value.shape\n",
        "        # Create a placeholder, to be overwritten by your code below.\n",
        "        output = torch.empty((N, T, D))\n",
        "        \n",
        "\n",
        "        # Get num of heads\n",
        "        H = self.h\n",
        "\n",
        "        # Compute key, query and value matrices from sequences\n",
        "        K = self.key(key).view(N, T, H, D//H).moveaxis(1, 2)\n",
        "        Q = self.query(query).view(N, S, H, D//H).moveaxis(1, 2)\n",
        "        V = self.value(value).view(N, T, H, D//H).moveaxis(1, 2)\n",
        "\n",
        "        # (N,H,S,D/H) @ (N,H,D/H,T) -> (N,H,S,T)\n",
        "        Y = Q @ K.transpose(2, 3) / self.scale\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            # Ensure small probabilities in softmax\n",
        "            Y = Y.masked_fill(attn_mask==0, float(\"-inf\"))\n",
        "        \n",
        "        # NOTE: Assignment says apply dropout after attention output. That does\n",
        "        # not work so dropout is applied right after softmax.\n",
        "\n",
        "        # (N,H,S,T) @ (N,H,T,D/H) -> (N,H,S,D/H)\n",
        "        Y = self.dropout(F.softmax(Y, dim=-1)) @ V\n",
        "        output = self.proj(Y.moveaxis(1, 2).reshape(N, S, D))\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer Normalization"
      ],
      "metadata": {
        "cell_id": "96fa5effdd954c498f1efa8cd0580bc3",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 62,
        "id": "ktUjeX1EIFRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the lecture, remember layer normalization where the values are normalized across the feature dimension, independently for each sample in the batch. For that, first calculate mean and standard-deviation across the feature dimension and then scale them appropriately such that the mean is 0 and the standard deviation is 1. Introduce **two sets of learnable parameters**, one for shifting the mean (addition) and one for scaling the variance (multiplication) the normalized features (i.e., two parameters for each feature). Tip: Use `nn.Parameter` for that."
      ],
      "metadata": {
        "cell_id": "fba0740f863c4787aa23494388944b49",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 141.953125,
        "id": "viV4QLsdIFRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$y_{\\textrm{norm}}=\\frac{x-\\mu}{\\sqrt{\\sigma+\\epsilon}}$\n",
        "\n",
        "$y=y_{\\textrm{norm}}\\cdot\\beta+\\alpha$"
      ],
      "metadata": {
        "cell_id": "5b0e5f8055a945929dd74b990ecd2a89",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 91.5,
        "id": "cmc2BxJQIFRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://i.stack.imgur.com/E3104.png\" alt=\"visualization of layer norm vs. batch norm\" width=\"420\">"
      ],
      "metadata": {
        "cell_id": "f96e811cce6d457f85eead1edae4692f",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 92.390625,
        "id": "b1yJ545WIFRJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "6d5af9330ebd43c5be334c4f3922031c",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "9c4ce5c0",
        "execution_start": 1656077679263,
        "execution_millis": 142,
        "output_cleared": true,
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 346,
        "id": "avZVAn-gIFRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adda96f4-2a3d-4349-9a05-efad90445a79"
      },
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, norm_shape):\n",
        "\n",
        "        \"\"\"\n",
        "        norm_shape: The dimension of the layer to be normalized.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.epsilon = 1e-5\n",
        "        self.alpha = nn.Parameter(torch.ones(norm_shape))  # seq_len,features\n",
        "        self.beta = nn.Parameter(torch.zeros(norm_shape))\n",
        "         \n",
        "    def forward(self,x: torch.Tensor):\n",
        "  \n",
        "        mean = x.mean(dim = -1, keepdim=True)   # Averaging over dim = (-1 ,-2):  hidden_n,  Q_len,\n",
        "        mean_x2 = (x ** 2).mean(dim = -1, keepdim=True) \n",
        "        var = mean_x2 - mean ** 2\n",
        "        sdt = torch.sqrt(var + self.epsilon)\n",
        "\n",
        "        x_norm = (x - mean) / sdt\n",
        "        x_norm = self.alpha * x_norm + self.beta\n",
        "        return x_norm\n",
        "        \n",
        "def _test():\n",
        "\n",
        "\n",
        "  x = torch.zeros([16, 10, 512])\n",
        "  print(x.shape)\n",
        "  ln = LayerNorm(x.shape[1:])\n",
        "\n",
        "  x = ln(x)\n",
        "  print(f\"{x.shape}output shape\")\n",
        "  print(f\"{ln.alpha.shape}www\")\n",
        "  print(ln.beta.shape)\n",
        "\n",
        "_test()\n",
        "\n",
        "x= torch.zeros([16, 10, 512])\n",
        "print(x.shape)\n",
        "mean = x.mean(dim=(0,1), keepdim=True)\n",
        "mean.shape\n",
        "\n",
        "x= torch.linspace(1, 24, 24).reshape(2,3,4)\n",
        "\n",
        "print(x)\n",
        "\n",
        "mean = x.mean(dim=(-1), keepdim=True)\n",
        "print(mean)\n",
        "print(x.shape[1:])\n",
        "y = torch.tensor([1,1,2,1]) \n",
        "\n",
        "z = mean * y\n",
        "z"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 10, 512])\n",
            "torch.Size([16, 10, 512])output shape\n",
            "torch.Size([10, 512])www\n",
            "torch.Size([10, 512])\n",
            "torch.Size([16, 10, 512])\n",
            "tensor([[[ 1.,  2.,  3.,  4.],\n",
            "         [ 5.,  6.,  7.,  8.],\n",
            "         [ 9., 10., 11., 12.]],\n",
            "\n",
            "        [[13., 14., 15., 16.],\n",
            "         [17., 18., 19., 20.],\n",
            "         [21., 22., 23., 24.]]])\n",
            "tensor([[[ 2.5000],\n",
            "         [ 6.5000],\n",
            "         [10.5000]],\n",
            "\n",
            "        [[14.5000],\n",
            "         [18.5000],\n",
            "         [22.5000]]])\n",
            "torch.Size([3, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.5000,  2.5000,  5.0000,  2.5000],\n",
              "         [ 6.5000,  6.5000, 13.0000,  6.5000],\n",
              "         [10.5000, 10.5000, 21.0000, 10.5000]],\n",
              "\n",
              "        [[14.5000, 14.5000, 29.0000, 14.5000],\n",
              "         [18.5000, 18.5000, 37.0000, 18.5000],\n",
              "         [22.5000, 22.5000, 45.0000, 22.5000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Block"
      ],
      "metadata": {
        "cell_id": "246bb7a8b64f4596b26778aa9ce5bc85",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 62,
        "id": "w79qfgHqIFRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we bring all ingredients together into a single module. Don't forget to add the residual connections."
      ],
      "metadata": {
        "cell_id": "93c32b55767c46049ffb13bc012bb500",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "0K1pnBtEIFRK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "4e040c8ebd5d42ddb8b00090dffdd960",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 241,
        "id": "_AGQD8YaIFRK"
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, hidden_n:int, h:int = 2,expansion_ratio=4,dropout=0.1,max_len=20):\n",
        "        \"\"\"\n",
        "        hidden_n: hidden dimension\n",
        "        h: number of heads\n",
        "        \"\"\"  \n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(hidden_n,h)\n",
        "        # self.norm1 = torch.nn.LayerNorm(hidden_n)\n",
        "        # self.norm2 = torch.nn.LayerNorm(hidden_n)\n",
        "\n",
        "        self.norm1 = LayerNorm(hidden_n)\n",
        "        self.norm2 = LayerNorm(hidden_n)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "          torch.nn.Linear(hidden_n,expansion_ratio * hidden_n),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Linear(expansion_ratio*hidden_n,hidden_n)\n",
        "            \n",
        "        )\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "    \n",
        "  def forward(self,value,key,query,mask=None):   #  there is no difference between q,k..,value in encoder block ,but you need to diverse them because in decoder the three input acutally differ\n",
        "        out_attention = self.attention.forward(value,key,query,mask)\n",
        "        out_firstnorm = self.norm1(query + out_attention)\n",
        "        out_firstnorm = self.dropout(out_firstnorm)\n",
        "        \n",
        "        out_feedforward = self.feedforward(out_firstnorm)\n",
        "        out = self.norm2(out_feedforward+out_firstnorm)\n",
        "        out = self.dropout(out)\n",
        "        return out"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Simple Transformer Architecture"
      ],
      "metadata": {
        "cell_id": "add8b0cdf6ef4a79bf2a71788029d617",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 70,
        "id": "PGZbOHD0IFRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's stack our transformer blocks and add an embedding layer for a simple transformer architecture. You are allowed to use `nn.Embedding` here."
      ],
      "metadata": {
        "cell_id": "0215525d6258493485ff71f3496128a2",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 74.78125,
        "id": "GGtEeeyRIFRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(      self,\n",
        "               embed_n,\n",
        "               hidden_n,\n",
        "               n,\n",
        "               h,\n",
        "               device,\n",
        "               dropout,\n",
        "               num_targ_vocab\n",
        "               ):\n",
        "    \n",
        "      \"\"\"\n",
        "      emb_n: embed_dim :number of token embeddings\n",
        "      hidden_n: hidden dimension\n",
        "      n: number of layers\n",
        "      h: number of heads per layer\n",
        "      \"\"\"\n",
        "      super().__init__()\n",
        "      self.device = device\n",
        "      self.embed1 = torch.nn.Embedding(embed_n,hidden_n)\n",
        "      #self.embed2 = torch.nn.Embedding(max_length,embed_n)   # seq len must be equal or smaller than max len\n",
        "      self.proj = torch.nn.Linear(hidden_n,num_targ_vocab)\n",
        "\n",
        "      self.layers = torch.nn.ModuleList( [ TransformerBlock(hidden_n,h) for i in range( n )] )\n",
        "\n",
        "\n",
        "  def forward(self,input,mask=None):    # input : N L\n",
        "      N,sequence_length = input.shape\n",
        "      #positional_encoding = torch.arange(0,sequence_length).expand(N,sequence_length).to(self.device)\n",
        "      #out = self.dropout(self.embed1(input) + self.embed2(positional_encoding))\n",
        "\n",
        "      out = self.embed1(input) # N S[o to L] -> N S D\n",
        "      \n",
        "      for layer in self.layers:\n",
        "        out = layer(out,out,out,mask)\n",
        "      # out = self.proj(out).reshape(N,sequence_length,-1)\n",
        "      return out"
      ],
      "metadata": {
        "id": "QPZPiU2X2SLi"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(\n",
        "    device\n",
        ")\n",
        "trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0], [1, 5, 6, 2, 4, 7, 6, 2]]).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = Transformer(\n",
        "            embed_n= 80,   # dim of word_embeded vector\n",
        "            hidden_n = 256,  # hidden dimension\n",
        "            n=3,       # num of layers\n",
        "            h=2,       # heads\n",
        "            device=\"cpu\",\n",
        "            dropout=0.1,\n",
        "            num_targ_vocab=64) # output vocabs space\n",
        "x1 = ((1/3) *torch.linspace(1,2*78,2*78)).reshape(2,-1).to(torch.int32).to(\n",
        "    device\n",
        ")\n",
        "x1\n",
        "\n",
        "out = model(x)\n",
        "print(out.shape)\n",
        "\n",
        "out = model(x1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cx-gL6p3F21",
        "outputId": "7310dfc1-d21d-46cc-8e55-bd4b679b10e3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "torch.Size([2, 9, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## POS-Tagging"
      ],
      "metadata": {
        "formattedRanges": [],
        "cell_id": "24ce63a017054111a0e7606078f244eb",
        "tags": [],
        "is_collapsed": false,
        "deepnote_cell_type": "text-cell-h2",
        "id": "iFdKaG6FIFRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-Of-Speech-Tagging (**POS-Tagging**) is a **sequence labeling problem** where we categorize words in a text in correspondence with a particular part of speech (e.g., \"noun\" or \"adjective\"). A few examples and classes are shown in the following table:"
      ],
      "metadata": {
        "cell_id": "46e6832e31434597932051c2d7d833db",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 74.78125,
        "id": "erJuzK-YIFRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|  POS Tag  |  Description  |  Examples  |\n",
        "|-----------|------------|------------|\n",
        "|  NN | Noun (singular, common) | mass, wind, ...  |\n",
        "|  NNP | Noun (singular, proper) | Obama, Liverpool, ...  |\n",
        "| CD  | Numeral (cardinal)  | 1890, 0.5, ...  |\n",
        "|  DT | Determiner  | all, any, ... |\n",
        "| JJ | Adjective (ordinal) | oiled, third, ... |\n",
        "... many more"
      ],
      "metadata": {
        "cell_id": "0b933b07b931423dae80af31abe46b69",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 200.734375,
        "id": "4mvGBAhWIFRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CoNLL2000 Dataset"
      ],
      "metadata": {
        "formattedRanges": [],
        "cell_id": "c1ea426748d34a2891270fb4c9189387",
        "tags": [],
        "is_collapsed": false,
        "deepnote_cell_type": "text-cell-h3",
        "id": "loJ1yga9IFRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load our dataset which is the **CoNLL2000 dataset** and look at an example."
      ],
      "metadata": {
        "cell_id": "ec19498428f042a09867d13bfcbbeaf1",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "2MHW6J-YIFRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install portalocker\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqLVP4-5i3vq",
        "outputId": "bf94eea9-fc9b-4a5c-cbc7-fdc1f28db07e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.7.0\n",
            "Python 3.9.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "56f8d97328eb45808c642c232c18ddeb",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "c7ccc53b",
        "execution_start": 1657123575378,
        "execution_millis": 3449,
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 329.375,
        "id": "Lv9iNSG_IFRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d156027d-e2f2-4a91-fb30-693c50b77e84"
      },
      "source": [
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.datasets import CoNLL2000Chunking\n",
        "import pandas as pd\n",
        "import portalocker\n",
        "train_df = pd.DataFrame(CoNLL2000Chunking()[0], columns=['words', 'pos_tags', 'chunk'])\n",
        "test_df = pd.DataFrame(CoNLL2000Chunking()[1], columns=['words', 'pos_tags', 'chunk'])\n",
        "\n",
        "train_src, train_tgt = train_df['words'].tolist(), train_df['pos_tags'].tolist()\n",
        "test_src, test_tgt = test_df['words'].tolist(), test_df['pos_tags'].tolist()\n",
        "\n",
        "print(train_src[2])\n",
        "print(train_tgt[2])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['But', 'analysts', 'reckon', 'underlying', 'support', 'for', 'sterling', 'has', 'been', 'eroded', 'by', 'the', 'chancellor', \"'s\", 'failure', 'to', 'announce', 'any', 'new', 'policy', 'measures', 'in', 'his', 'Mansion', 'House', 'speech', 'last', 'Thursday', '.']\n",
            "['CC', 'NNS', 'VBP', 'VBG', 'NN', 'IN', 'NN', 'VBZ', 'VBN', 'VBN', 'IN', 'DT', 'NN', 'POS', 'NN', 'TO', 'VB', 'DT', 'JJ', 'NN', 'NNS', 'IN', 'PRP$', 'NNP', 'NNP', 'NN', 'JJ', 'NNP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to create a vocabulary. Our dataset is already tokenized. However, we need to assign ids to them in order to input them to the embedding layer. We also need the number of embeddings (`num_embeddings`) for the size of our lookup table of `nn.Embedding`.\n",
        "\n",
        "Thus, we will iterate over all sentences replace them with ids and the mapping to our vocabulary. It'll be handy to have two different mappings, from id to token, as well as, from token to id. Note that we will add a special token `<unk>` with id `0` for words that are unknown (that are not in the training dataset but could possibly be in the test dataset)."
      ],
      "metadata": {
        "cell_id": "555caa09a6714a63a9cdee39264291f7",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 178.34375,
        "id": "gorNrQNTIFRM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "9b665796e64d4aa694d1718b5156294d",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2276b8b9",
        "execution_start": 1656084179768,
        "execution_millis": 1512,
        "output_cleared": true,
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 148,
        "id": "5aOPqcAlIFRM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "48c10a2a-97a8-4ab3-a76f-e3c588c02f8e"
      },
      "source": [
        "from collections import Counter\n",
        "from os import sendfile\n",
        "from collections import OrderedDict\n",
        "\n",
        "\"\"\"\"\"\n",
        "imporvement: things to do\n",
        "\n",
        "to much indexs , sort it by frequencie and discard words less frequently appear\n",
        "\"\"\"\"\"\n",
        "\n",
        "vocabulary_id2token : dict = {0: '<unk>'}\n",
        "vocabulary_token2id : dict = {'<unk>': 0}\n",
        "\n",
        "# get all words\n",
        "word_list = [word    for sentence in train_src for word in sentence]\n",
        "\n",
        "# sort by frequency\n",
        "count = Counter(word_list)\n",
        "result = sorted(word_list, key=lambda x: count[x],reverse=True)\n",
        "\n",
        "# reomve redundants and andd <unk>\n",
        "word_list_no_redundant = list(OrderedDict.fromkeys(result))[:8000]\n",
        "\n",
        "# show\n",
        "for i in range(300):\n",
        "    print(word_list_no_redundant[i])\n",
        "\n",
        "print(f'lenth no redundant:{len(word_list_no_redundant)}')\n",
        "word_list_no_redundant.insert(0,'<unk>')\n",
        "\n",
        "# create index list\n",
        "idx = [ i for i in range(len(word_list_no_redundant))]\n",
        "\n",
        "# create token 2id and id to token dicts\n",
        "vocabulary_token2id = dict(zip(word_list_no_redundant,idx))\n",
        "vocabulary_id2token =  {v: k for k, v in vocabulary_token2id.items()} # swap key value in last dict\n",
        "vocabulary_token2id\n",
        "\n",
        "print(f'lenth id list:{len(vocabulary_id2token)}')\n",
        "\n",
        "# test\n",
        "print(vocabulary_token2id['if'])\n",
        "print(vocabulary_id2token[107])\n",
        "vocabulary_id2token[vocabulary_token2id['if']]\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107\n",
            "if\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'if'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "rand_idx = [random.randint(0, 10) for _ in range(100)]\n",
        "\n",
        "print(result)\n",
        "\n",
        "my_list = ['JACK', 'JACK', 'china', 'africa', 'upstairs', 'upstars', '!', '!']\n",
        "result = list(set(my_list))\n",
        "\n",
        "for item in my_list:\n",
        "    if item not in result:\n",
        "        result.append(item)\n",
        "\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "id": "CCCkVtxlF5XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do the same for our classes:"
      ],
      "metadata": {
        "cell_id": "eed144592b0a4aa9a752fab5230b27e6",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "NiqDTK7NIFRN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "a4401fdd42024ef9b0af6c95af4ff963",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 133,
        "id": "cpJQB37hIFRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ead2cab-ef71-4f17-c6ee-43d028a5839b"
      },
      "source": [
        "classes_id2name : dict = {}\n",
        "classes_name2id : dict = {}\n",
        "\n",
        "token_list = [token for sentence in train_tgt + test_tgt for token in sentence]\n",
        "\n",
        "my_list = token_list\n",
        "count = Counter(my_list)\n",
        "result = sorted(my_list, key=lambda x: count[x],reverse=True)\n",
        "token_list_no_redun =  list(set(result))\n",
        "\n",
        "print(f'lenth token list:{len(token_list_no_redun)}')\n",
        "idx = [ i for i in range(len(token_list_no_redun))]\n",
        "\n",
        "classes_name2id = dict(zip(token_list_no_redun,idx))\n",
        "classes_id2name =  {v: k for k, v in classes_name2id.items()}\n",
        "\n",
        "# test \n",
        "print(classes_name2id['NN'])\n",
        "print(classes_id2name[32])\n",
        "\n",
        "print(classes_id2name[19])\n",
        "classes_name2id['VBZ']"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenth token list:44\n",
            "32\n",
            "NN\n",
            "VBZ\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from collections import Counter\n",
        "\n",
        "# my_list = [1, 2, 3, 1, 2, 3, 3, 4]\n",
        "# count = Counter(my_list)\n",
        "# result = sorted(my_list, key=lambda x: count[x],reverse=True)\n",
        "\n",
        "\n",
        "# print(result)\n",
        "# result_no_redun = list(dict.fromkeys(result))\n",
        "# print(result_no_redun)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svwct4jRCXOQ",
        "outputId": "4612a87e-8794-48ed-afd0-3ab2aa9f7289"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 3, 3, 1, 2, 1, 2, 4]\n",
            "[3, 1, 2, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's use PyTorch's `Dataset` and `DataLoader` for help us batching our data. Let's also replace tokens and classes with our ids. For that, complete `get_token_ids` and `get_class_ids`."
      ],
      "metadata": {
        "cell_id": "ef26b718c8654c7cb211c7542430ee79",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 74.78125,
        "id": "fyjGD9vOIFRN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "33964355330b45ad98f64b88799e8672",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a6bcb220",
        "execution_start": 1656333952181,
        "execution_millis": 2,
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 508,
        "id": "MWL5PNGuIFRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c4edbd-6074-4781-e522-979748c44e22"
      },
      "source": [
        "def get_token_ids(src):\n",
        "    \"\"\"\n",
        "    Usage:get_token_ids( ['word1','word2'])\n",
        "\n",
        "    \"\"\"\n",
        "    #result = [vocabulary_token2id[elm] for elm in src]\n",
        "    result = [vocabulary_token2id[elm] if elm in vocabulary_token2id else 0 for elm in src]\n",
        "    #result = vocabulary_token2id[src_tuple]\n",
        "    return result\n",
        "\n",
        "\n",
        "# TEST\n",
        "\n",
        "print(get_token_ids(['<unk>','if']))\n",
        "print(get_token_ids(['have']))\n",
        "\n",
        "def get_class_ids(tgt):                       #  maybe need some justification\n",
        "    result = [classes_name2id[elm] for elm in tgt]\n",
        "    return result\n",
        "# TEST\n",
        "get_class_ids(['NN','VBZ'])\n",
        "\n",
        "\n",
        "'''\n",
        "Deine Class ConllDataset\n",
        "'''\n",
        "\n",
        "class ConllDataset(Dataset):\n",
        "  def __init__(self, src, tgt):\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        src = self.src[index]\n",
        "        tgt = self.tgt[index]\n",
        "        \n",
        "        return {\n",
        "            'src': get_token_ids(src),\n",
        "            'tgt': get_class_ids(tgt),\n",
        "        }\n",
        "\n",
        "train_dataset = ConllDataset(train_src, train_tgt)\n",
        "test_dataset = ConllDataset(test_src, test_tgt)\n",
        "\n",
        "\n",
        "\n",
        "what = train_dataset[0]\n",
        "\n",
        "# print(what)\n",
        "t =what['src']\n",
        "# print(t)\n",
        "# w =what['tgt']\n",
        "# print(w)\n",
        "\n",
        "# helpler functions\n",
        "\n",
        "def idtowords(id):\n",
        "  result = [vocabulary_id2token[i] for i in id]\n",
        "  return result\n",
        "def id2name(id):\n",
        "  result = [classes_id2name[i] for i in id]\n",
        "  return result\n",
        "\n",
        "# test \n",
        "sr = idtowords(what['src'])\n",
        "tg = id2name(what['tgt'])\n",
        "print(sr , len(sr))\n",
        "print(tg,len(tg))\n",
        "print(get_token_ids(idtowords(what['src'])) == what['src'])\n",
        "print(get_class_ids(id2name(what['tgt'])) == what['tgt'])\n",
        "\n",
        "print(get_token_ids(['if']))\n",
        "print(get_token_ids(['<unk>','if']))\n",
        "print(get_token_ids(['qwewqeqw','if','unknown_word']))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 107]\n",
            "[34]\n",
            "['<unk>', 'in', 'the', 'pound', 'is', 'widely', 'expected', 'to', 'take', 'another', 'sharp', 'dive', 'if', 'trade', 'figures', 'for', 'September', ',', 'due', 'for', 'release', 'tomorrow', ',', 'fail', 'to', 'show', 'a', 'substantial', 'improvement', 'from', 'July', 'and', 'August', \"'s\", 'near-record', '<unk>', '.'] 37\n",
            "['NN', 'IN', 'DT', 'NN', 'VBZ', 'RB', 'VBN', 'TO', 'VB', 'DT', 'JJ', 'NN', 'IN', 'NN', 'NNS', 'IN', 'NNP', ',', 'JJ', 'IN', 'NN', 'NN', ',', 'VB', 'TO', 'VB', 'DT', 'JJ', 'NN', 'IN', 'NNP', 'CC', 'NNP', 'POS', 'JJ', 'NNS', '.'] 37\n",
            "True\n",
            "True\n",
            "[107]\n",
            "[0, 107]\n",
            "[0, 107, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a **batch size of 32**."
      ],
      "metadata": {
        "cell_id": "ce970c07a9ca4b6ab5a4ee941f3492b9",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "r8orJriQIFRO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "e66f66e38e4343a8ac9237e4e9bf74e5",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "f1c68216",
        "execution_start": 1656086903728,
        "execution_millis": 49,
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 76,
        "id": "uU4VY7CZIFRO"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# trainloader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,drop_last=True)  # is error triggering ,as each item inside batch doenst share same size\n",
        "# testloader = DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "# dataiter = iter(trainloader)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, since our examples are of different length, we need to pad shorter examples to the length of the example with the maximum length in our batch. So, let's define a special **padding token** in our vocabulary:"
      ],
      "metadata": {
        "cell_id": "a4c1832e408347d89d304e7870522878",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 74.78125,
        "id": "bcdM0L7QIFRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padding_token = '<blank>' # index = 1\n",
        "from collections import Counter\n",
        "from os import sendfile\n",
        "from collections import OrderedDict\n",
        "\n",
        "\"\"\"\"\"\n",
        "imporvement: things to do\n",
        "\n",
        "to much indexs , sort it by frequencie and discard words less frequently appear\n",
        "\"\"\"\"\"\n",
        "\n",
        "vocabulary_id2token : dict = {0: '<unk>'}\n",
        "vocabulary_token2id : dict = {'<unk>': 0}\n",
        "\n",
        "# get all words\n",
        "word_list = [word    for sentence in train_src for word in sentence]\n",
        "\n",
        "# sort by frequency\n",
        "count = Counter(word_list)\n",
        "result = sorted(word_list, key=lambda x: count[x],reverse=True)\n",
        "\n",
        "# reomve redundants and andd <unk>\n",
        "word_list_no_redundant = list(OrderedDict.fromkeys(result))[:8000]\n",
        "\n",
        "# show\n",
        "for i in range(300):\n",
        "    print(word_list_no_redundant[i])\n",
        "\n",
        "print(f'lenth no redundant:{len(word_list_no_redundant)}')\n",
        "word_list_no_redundant.insert(0,'<unk>')\n",
        "word_list_no_redundant.insert(1,'<blank>')\n",
        "\n",
        "# create index list\n",
        "idx = [ i for i in range(len(word_list_no_redundant))]\n",
        "\n",
        "# create token 2id and id to token dicts\n",
        "vocabulary_token2id = dict(zip(word_list_no_redundant,idx))\n",
        "vocabulary_id2token =  {v: k for k, v in vocabulary_token2id.items()} # swap key value in last dict\n",
        "vocabulary_token2id\n",
        "\n",
        "print(f'lenth id list:{len(vocabulary_id2token)}')\n",
        "\n",
        "\n",
        "# test\n",
        "print(vocabulary_id2token[0])\n",
        "print(vocabulary_token2id[vocabulary_id2token[0]])\n",
        "print(vocabulary_id2token[1])\n",
        "print(vocabulary_token2id[vocabulary_id2token[1]])\n",
        "for n in [random.randint(0,500) for _ in range(10)]:\n",
        "  \n",
        "  print(vocabulary_id2token[n])\n",
        "  print(vocabulary_token2id[vocabulary_id2token[n]])\n",
        "  print(vocabulary_id2token[n])\n",
        "  print(vocabulary_token2id[vocabulary_id2token[n]])\n",
        "  print(vocabulary_id2token[vocabulary_token2id[vocabulary_id2token[n]]])\n",
        "  vocabulary_id2token[n]\n",
        "  print('~'*10)\n",
        "  #vocabulary_id2token[n]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKjJm-iiMGj3",
        "outputId": "64667529-82fe-4792-94a3-82d6e5cecbf6"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",\n",
            "the\n",
            ".\n",
            "of\n",
            "to\n",
            "a\n",
            "and\n",
            "in\n",
            "'s\n",
            "for\n",
            "that\n",
            "$\n",
            "``\n",
            "The\n",
            "''\n",
            "is\n",
            "said\n",
            "%\n",
            "on\n",
            "from\n",
            "million\n",
            "at\n",
            "it\n",
            "by\n",
            "as\n",
            "was\n",
            "be\n",
            "with\n",
            "are\n",
            "Mr.\n",
            "n't\n",
            "its\n",
            "an\n",
            "have\n",
            "has\n",
            "or\n",
            "will\n",
            "he\n",
            "company\n",
            "year\n",
            "were\n",
            "says\n",
            "they\n",
            "would\n",
            "which\n",
            "about\n",
            "--\n",
            "their\n",
            "more\n",
            "In\n",
            "share\n",
            "this\n",
            "up\n",
            "But\n",
            "market\n",
            "but\n",
            "billion\n",
            "also\n",
            "than\n",
            "had\n",
            "who\n",
            "been\n",
            "his\n",
            "other\n",
            "I\n",
            ":\n",
            "some\n",
            "new\n",
            "one\n",
            "U.S.\n",
            "out\n",
            "Corp.\n",
            "not\n",
            "New\n",
            "years\n",
            "all\n",
            ";\n",
            "-RRB-\n",
            "could\n",
            "Inc.\n",
            "-LRB-\n",
            "into\n",
            "stock\n",
            "It\n",
            "because\n",
            "can\n",
            "last\n",
            "after\n",
            "when\n",
            "only\n",
            "two\n",
            "shares\n",
            "cents\n",
            "over\n",
            "do\n",
            "&\n",
            "rose\n",
            "York\n",
            "business\n",
            "sales\n",
            "price\n",
            "quarter\n",
            "trading\n",
            "companies\n",
            "such\n",
            "may\n",
            "if\n",
            "A\n",
            "Co.\n",
            "earnings\n",
            "most\n",
            "any\n",
            "investors\n",
            "people\n",
            "first\n",
            "He\n",
            "government\n",
            "time\n",
            "investment\n",
            "there\n",
            "net\n",
            "many\n",
            "interest\n",
            "we\n",
            "week\n",
            "president\n",
            "much\n",
            "'\n",
            "prices\n",
            "now\n",
            "yesterday\n",
            "down\n",
            "you\n",
            "them\n",
            "months\n",
            "stocks\n",
            "say\n",
            "1\n",
            "income\n",
            "earlier\n",
            "group\n",
            "bonds\n",
            "no\n",
            "make\n",
            "what\n",
            "We\n",
            "so\n",
            "state\n",
            "through\n",
            "money\n",
            "San\n",
            "does\n",
            "just\n",
            "did\n",
            "while\n",
            "rate\n",
            "And\n",
            "like\n",
            "major\n",
            "American\n",
            "three\n",
            "For\n",
            "earthquake\n",
            "federal\n",
            "still\n",
            "next\n",
            "10\n",
            "month\n",
            "even\n",
            "chief\n",
            "rates\n",
            "made\n",
            "officials\n",
            "bank\n",
            "tax\n",
            "expected\n",
            "products\n",
            "off\n",
            "That\n",
            "get\n",
            "fell\n",
            "higher\n",
            "chairman\n",
            "sell\n",
            "California\n",
            "back\n",
            "plan\n",
            "operations\n",
            "unit\n",
            "industry\n",
            "before\n",
            "those\n",
            "financial\n",
            "increase\n",
            "reported\n",
            "days\n",
            "Francisco\n",
            "since\n",
            "Exchange\n",
            "part\n",
            "costs\n",
            "lower\n",
            "'re\n",
            "executive\n",
            "profit\n",
            "both\n",
            "funds\n",
            "ago\n",
            "own\n",
            "buy\n",
            "take\n",
            "being\n",
            "30\n",
            "pay\n",
            "these\n",
            "British\n",
            "sale\n",
            "well\n",
            "They\n",
            "way\n",
            "1988\n",
            "under\n",
            "firm\n",
            "past\n",
            "House\n",
            "increased\n",
            "15\n",
            "work\n",
            "assets\n",
            "area\n",
            "against\n",
            "added\n",
            "high\n",
            "Friday\n",
            "plans\n",
            "good\n",
            "program\n",
            "securities\n",
            "insurance\n",
            "few\n",
            "revenue\n",
            "big\n",
            "bid\n",
            "National\n",
            "due\n",
            "analysts\n",
            "should\n",
            "between\n",
            "debt\n",
            "This\n",
            "8\n",
            "several\n",
            "used\n",
            "?\n",
            "issues\n",
            "my\n",
            "50\n",
            "policy\n",
            "loss\n",
            "third-quarter\n",
            "sold\n",
            "recent\n",
            "then\n",
            "Bank\n",
            "East\n",
            "based\n",
            "cost\n",
            "how\n",
            "results\n",
            "very\n",
            "want\n",
            "including\n",
            "Stock\n",
            "period\n",
            "loans\n",
            "If\n",
            "closed\n",
            "end\n",
            "might\n",
            "think\n",
            "banks\n",
            "same\n",
            "help\n",
            "Congress\n",
            "during\n",
            "issue\n",
            "20\n",
            "director\n",
            "where\n",
            "Street\n",
            "growth\n",
            "spokesman\n",
            "number\n",
            "least\n",
            "going\n",
            "International\n",
            "five\n",
            "less\n",
            "computer\n",
            "too\n",
            "lenth no redundant:8000\n",
            "lenth id list:8002\n",
            "<unk>\n",
            "0\n",
            "<blank>\n",
            "1\n",
            "100\n",
            "313\n",
            "100\n",
            "313\n",
            "100\n",
            "~~~~~~~~~~\n",
            "corporate\n",
            "394\n",
            "corporate\n",
            "394\n",
            "corporate\n",
            "~~~~~~~~~~\n",
            "are\n",
            "30\n",
            "are\n",
            "30\n",
            "are\n",
            "~~~~~~~~~~\n",
            "3\n",
            "384\n",
            "3\n",
            "384\n",
            "3\n",
            "~~~~~~~~~~\n",
            "had\n",
            "61\n",
            "had\n",
            "61\n",
            "had\n",
            "~~~~~~~~~~\n",
            "House\n",
            "226\n",
            "House\n",
            "226\n",
            "House\n",
            "~~~~~~~~~~\n",
            "major\n",
            "160\n",
            "major\n",
            "160\n",
            "major\n",
            "~~~~~~~~~~\n",
            "move\n",
            "391\n",
            "move\n",
            "391\n",
            "move\n",
            "~~~~~~~~~~\n",
            "they\n",
            "44\n",
            "they\n",
            "44\n",
            "they\n",
            "~~~~~~~~~~\n",
            "back\n",
            "187\n",
            "back\n",
            "187\n",
            "back\n",
            "~~~~~~~~~~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes_id2name : dict = {}\n",
        "classes_name2id : dict = {}\n",
        "\n",
        "token_list = [token for sentence in train_tgt + test_tgt for token in sentence]\n",
        "\n",
        "my_list = token_list\n",
        "count = Counter(my_list)\n",
        "result = sorted(my_list, key=lambda x: count[x],reverse=True)\n",
        "token_list_no_redun =  list(set(result))\n",
        "\n",
        "token_list_no_redun.insert(0,'<blank>')\n",
        "\n",
        "print(f'lenth token list:{len(token_list_no_redun)}')\n",
        "idx = [ i for i in range(len(token_list_no_redun))]\n",
        "\n",
        "classes_name2id = dict(zip(token_list_no_redun,idx))\n",
        "classes_id2name =  {v: k for k, v in classes_name2id.items()}\n",
        "\n",
        "# test \n",
        "print(classes_name2id['<blank>'])\n",
        "print(classes_id2name[0])\n",
        "print(classes_name2id['<blank>'])\n",
        "print(classes_name2id['NN'])\n",
        "print(classes_id2name[33])\n",
        "print(classes_id2name[10])\n",
        "classes_name2id['WDT']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_l1sWxPO4O5",
        "outputId": "592e4ccf-5fdf-4165-f89f-4b2af42b2a4e"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "<blank>\n",
            "0\n",
            "33\n",
            "NN\n",
            "WDT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `collate_fn` is the function that actually receives a batch and needs to add the padding tokens, then returns `src` and `tgt` as `Tensor`s of size `[B, S]` where `B` is our batch size and `S` our maximum sequence length. This function should additionally return a `mask`, a `Tensor` with binary values to indicate whether the specific element is a padding token or not (0 if it's a padding token, 1 if not), such that we can ignore padding tokens in our attention mechanism and loss calculation. "
      ],
      "metadata": {
        "cell_id": "c7b65a2d6b654c8bbe59ad7432758a8a",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 119.5625,
        "id": "mEnhslebIFRO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "9266354695a646ebbd776e4290baa002",
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d3107fb6",
        "execution_start": 1656086903777,
        "execution_millis": 0,
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 238,
        "id": "fGOAlitcIFRP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "833d3833-335c-4235-bbdf-a6a4fbaf3d67"
      },
      "source": [
        "\"\"\"\n",
        "batch:  list of dictionaries  with keys src and tgt (in index) (as defined in ConllDataset)# \n",
        "\"\"\"\n",
        "#[B,S] = [BATCH_SIZE,MAX_SEQ_LENGTH]    \n",
        "\n",
        "\n",
        "\n",
        "#one Batch shape:   N, seq_len, embed_len\n",
        "\n",
        "# this function moves tensors to cuda , when train on gpu mode is True\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "\n",
        "def create_tensor(tensor):              \n",
        "\n",
        "  return tensor.int().to(device)\n",
        "\n",
        "# test\n",
        "tes =create_tensor(torch.tensor([1,2,3]))\n",
        "tes.is_cuda \n",
        "\n",
        "'''\n",
        "define callate_fn\n",
        "'''\n",
        "def collate_fn(batch):   #list[dict]) -> dict[str, Tensor]:\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    batch: *** list of dictionaries **** with keys src and tgt (as defined in ConllDataset)\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    S = max_seqlen = 50\n",
        "    seq_lenths = [min(S,len(batch[i]['src'])) for i in range(len(batch))]\n",
        "    #S = max(seq_lenths)  \n",
        "    \n",
        "    B = len(batch)\n",
        "    # Padding the input vector with zero to maximal seq_lenth\n",
        "    src = torch.ones(B,S)  # A place holder for padding\n",
        "    mask = torch.zeros(B,S) # same For mask \n",
        "    tgt = torch.zeros(B,S)  # A place holder for padding\n",
        "    \n",
        "    # paste them onto padded holder\n",
        "    for idx in range(B):        # 2. paste each line of name_sequences onto seq_tensor\n",
        "      \"\"\" Truncanate \"\"\"\n",
        "      src[ idx,: seq_lenths[idx] ] = torch.LongTensor(batch[idx]['src'][:seq_lenths[idx]])\n",
        "      mask[ idx,: seq_lenths[idx] ] = 1\n",
        "      tgt[ idx,: seq_lenths[idx] ] = torch.LongTensor( batch[idx]['tgt'][:seq_lenths[idx]] )  \n",
        "\n",
        "    \"\"\" cast to Tensor with certain type \"\"\"\n",
        "    src = create_tensor(src)\n",
        "    tgt = create_tensor(tgt)\n",
        "    mask = create_tensor(mask)\n",
        "    dic_r = {\n",
        "        'src': src,\n",
        "        'tgt': tgt,\n",
        "        'mask': mask,   # src mask\n",
        "    }\n",
        "\n",
        "    return dic_r\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# test \n",
        "\n",
        "list1 = {\n",
        "            'src': [0, 14],\n",
        "            'tgt': [0, 14],\n",
        "        }\n",
        "\n",
        "list2 = {\n",
        "            'src': [1,13,14,15],\n",
        "            'tgt': [1,13,14,15],\n",
        "        }\n",
        "\n",
        "list3 = {\n",
        "    'src': [i for i in range(60)],\n",
        "    'tgt': [i for i in range(60)],\n",
        "}\n",
        "batch = [list1,list2 ,list3] \n",
        "\n",
        "print(f\"batch as input:{batch}\")\n",
        "# batch[0]['src']   \n",
        "# # seq_lenths = [len(batch[i]['src']) for i in len(batch)]\n",
        "\n",
        "# seq_lenths = [len(batch[i]['src']) for i in range(len(batch))]\n",
        "# S = max(seq_lenths)\n",
        "# B = len(batch)\n",
        "# print(seq_lenths,S,B)\n",
        "# src = torch.ones(B,S)  # A place holder for padding\n",
        "# for idx in range(B):        # 2. paste each line of name_sequences onto seq_tensor\n",
        "#   src[ idx,: seq_lenths[idx] ] = torch.LongTensor(batch[idx]['src'])\n",
        "# src\n",
        "# srf = create_tensor(src)\n",
        "# srf\n",
        "# # seq_lenths\n",
        "\n",
        "a = collate_fn(batch)\n",
        "for i in range (len(batch)):\n",
        "    print(a['src'][i])\n",
        "    print([  vocabulary_id2token[wid.item()] for wid in a['src'][i]])\n",
        "    print(a['tgt'][i])\n",
        "    print(a['mask'][i])\n",
        "\n",
        "classes_id2name[torch.tensor(13).item()]"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch as input:[{'src': [0, 14], 'tgt': [0, 14]}, {'src': [1, 13, 14, 15], 'tgt': [1, 13, 14, 15]}, {'src': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], 'tgt': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]}]\n",
            "tensor([ 0, 14,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "       dtype=torch.int32)\n",
            "['<unk>', '``', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>']\n",
            "tensor([ 0, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       dtype=torch.int32)\n",
            "tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0], dtype=torch.int32)\n",
            "tensor([ 1, 13, 14, 15,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "       dtype=torch.int32)\n",
            "['<blank>', '$', '``', 'The', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>']\n",
            "tensor([ 1, 13, 14, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "       dtype=torch.int32)\n",
            "tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0], dtype=torch.int32)\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
            "       dtype=torch.int32)\n",
            "['<unk>', '<blank>', ',', 'the', '.', 'of', 'to', 'a', 'and', 'in', \"'s\", 'for', 'that', '$', '``', 'The', \"''\", 'is', 'said', '%', 'on', 'from', 'million', 'at', 'it', 'by', 'as', 'was', 'be', 'with', 'are', 'Mr.', \"n't\", 'its', 'an', 'have', 'has', 'or', 'will', 'he', 'company', 'year', 'were', 'says', 'they', 'would', 'which', 'about', '--', 'their']\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
            "       dtype=torch.int32)\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1], dtype=torch.int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RBR'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_src_test = [['Chancellor', 'of', 'the', 'Exchequer', 'Nigel', 'Lawson', \"'s\"],\n",
        "#                   ['Confidence', 'in', 'the', 'pound'],\n",
        "#                   ['But', 'analysts', 'reckon', 'underlying', 'support']\n",
        "#                   ]\n",
        "\n",
        "# train_tgt_test = [['NNP', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'POS'],\n",
        "#                   ['NN', 'IN', 'DT', 'NN'],\n",
        "#                   ['CC', 'NNS', 'VBP', 'VBG', 'NN']\n",
        "#                   ]\n",
        "#\n",
        "\n",
        "train_src_test = train_src[:3]\n",
        "\n",
        "train_tgt_test = train_tgt[:3]\n",
        "train_dataset_test = ConllDataset(train_src_test, train_tgt_test)\n",
        "train_data_loader_test = DataLoader(train_dataset_test, collate_fn=collate_fn, batch_size= 2, shuffle=False)\n",
        "\n",
        "dataiter_test = iter(train_data_loader_test)\n",
        "\n",
        "dic_r_test = next(dataiter_test)\n",
        "\n",
        "for i in range(2):\n",
        "  print(dic_r_test['src'][i])\n",
        "  print(dic_r_test['tgt'][i])\n",
        "  print(dic_r_test['mask'][i])\n",
        "  print(len(dic_r_test['src'][i]))\n",
        "  print(len(dic_r_test['tgt'][i]))\n",
        "  print(len(dic_r_test['mask'][i]))\n",
        "  print(idtowords(dic_r_test['src'][i].tolist()))\n",
        "  print(id2name(dic_r_test['tgt'][i].tolist()))\n",
        "\n",
        "  dic_r_test['src'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgm2GrZEKpH_",
        "outputId": "a2710050-304a-4361-d3be-527532cc0ca9"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With that, we can use PyTorch's `DataLoader` which will shuffle and batch our data automatically."
      ],
      "metadata": {
        "cell_id": "27c262f705004bac83e8306a99ba8bcb",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "9O9eaX6oIFRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "create train_data_loader  and test_data_loader...\n",
        "\"\"\"\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=32, shuffle=True)#,drop_last=True\n",
        "test_data_loader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=32, shuffle=True)#,drop_last=True\n",
        "\n",
        "\n",
        "# test\n",
        "\n",
        "\n",
        "# dataiter = iter(train_data_loader)\n",
        "\n",
        "# dic_r= next(dataiter)\n",
        "\n",
        "# for i in range(2):\n",
        "#   print(dic_r['src'][i])\n",
        "#   print(dic_r['tgt'][i])\n",
        "#   print(dic_r['mask'][i])\n",
        "#   print(len(dic_r['src'][i]))\n",
        "#   print(len(dic_r['tgt'][i]))\n",
        "#   print(len(dic_r['mask'][i]))\n",
        "#   print(idtowords(dic_r['src'][i].tolist()))\n",
        "#   print(id2name(dic_r['tgt'][i].tolist()))\n",
        "\n",
        "\"\"\"  test of test_data_loader \"\"\"\n",
        "\n",
        "dataiter = iter(test_data_loader)\n",
        "\n",
        "dic_r= next(dataiter)\n",
        "\n",
        "for i in range(2):\n",
        "  print(dic_r['src'][i])\n",
        "  print(dic_r['tgt'][i])\n",
        "  print(dic_r['mask'][i])\n",
        "  print(len(dic_r['src'][i]))\n",
        "  print(len(dic_r['tgt'][i]))\n",
        "  print(len(dic_r['mask'][i]))\n",
        "  print(idtowords(dic_r['src'][i].tolist()))\n",
        "  print(id2name(dic_r['tgt'][i].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWp-U4iyWFNu",
        "outputId": "fc18325a-e6cb-49cd-bd3c-cd066d193c18"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "formattedRanges": [],
        "cell_id": "803ef4d85f0a4e2fbcb2ee182520c7f5",
        "tags": [],
        "is_collapsed": false,
        "deepnote_cell_type": "text-cell-h3",
        "id": "8KVkLLBSIFRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build a transformer model with three layers, three attention heads and an embedding dimension of 128. Also, let's not forget to add a classification head to our model."
      ],
      "metadata": {
        "cell_id": "06f55de40ea248099cbf94bacf9b1268",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 74.78125,
        "id": "DrRtqkmfIFRQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "5f1f177f8cf343f1bd763f05a8c8703d",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 223,
        "id": "oCqiI40FIFRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cdda7e5-7f62-41da-a8a0-4b0a908d3e14"
      },
      "source": [
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self,  input_dim, trg_vocab_size,max_seqlen=50 ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_layer = nn.Linear(input_dim * max_seqlen , 2*input_dim* max_seqlen) \n",
        "        self.activation_1 = nn.ReLU()\n",
        "        self.output_layer = nn.Linear(2*input_dim * max_seqlen, max_seqlen * trg_vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        N,L,S = x.shape\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.hidden_layer(x)\n",
        "        x = self.activation_1(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x.reshape(N,L,-1)\n",
        "        # return x\n",
        "      \n",
        "\n",
        "class CoNLL2000Transformer(nn.Module):\n",
        "    def __init__(self, transformer, classifier):\n",
        "        super().__init__()\n",
        "        self.transformer = transformer\n",
        "        self.classification_layer = classifier\n",
        "\n",
        "    def forward(self,input):\n",
        "        out = self.transformer(input)\n",
        "        out = self.classification_layer(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "transformermodel = Transformer(\n",
        "            embed_n=80001,   # dim of word_embeded vector\n",
        "            hidden_n=256,  # hidden dimension\n",
        "            n=3,       # num of layers\n",
        "            h=2,       # heads\n",
        "            device=\"cpu\",\n",
        "            dropout=0.1,\n",
        "            num_targ_vocab=64).to(device) # output vocabs space\n",
        "\n",
        "max_seqlen = 9\n",
        "trg_vocab_size = 50\n",
        "classificationhead = ClassificationHead(input_dim=256, trg_vocab_size= 45,max_seqlen=50).to(device)\n",
        "\n",
        "classificationhead(transformermodel(x)).shape\n",
        "\n",
        "model = CoNLL2000Transformer(transformermodel, classificationhead).to(device)\n",
        "transformermodel(x).shape\n",
        "\n",
        "print(x.shape, model.forward(x).shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "cell_id": "f5aafb3762974b07be3a8a89899db999",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 62,
        "id": "eyBlYbS_IFRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the **AdamW** optimizer from the `torch.optim` module and choose the most appropriate loss function for our task."
      ],
      "metadata": {
        "cell_id": "965bfa0ea57d4052aabfdba6904f65de",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "mudrNieKIFRQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "5101fa497d074916b870e1e4fe9147d4",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 79,
        "id": "NNKrzK2aIFRR"
      },
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "Learning_rate = 0.005\n",
        "optimizer = torch.optim.AdamW(model.parameters(),Learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a basic training loop and train the network for three epochs.\n",
        "- Use everything we've built to far, including `train_data_loader`, `model`, `optimizer` and `criterion`.\n",
        "- At every 50th step print the average loss of the last 50 steps. \n",
        "- It is suggested to make a basic training procedure to work on the CPU first. Once it successfully runs on the CPU, you can switch to the GPU (click on change runtime and add an hardware accelerator if you use Colab) and run for the whole three epochs. Note: For this to work, you need to transfer the `model` and the input tensors to the GPU memory. This simply works by calling `.to(device)` on the model and tensors, where `device` and either be `cpu` or `cuda` (for the GPU)."
      ],
      "metadata": {
        "cell_id": "de1bb8eda67644db93779c72899e588c",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 220.734375,
        "id": "cB-5UzMFIFRR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "19af38a10aa64403b865dde3603d43e3",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 169,
        "id": "VmVQbcldIFRR"
      },
      "source": [
        "\"\"\"\n",
        "try to overfit one single batch first\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(dic_r['src'].shape)\n",
        "\n",
        "print(x.shape, model.forward(dic_r['src']).shape)\n",
        "\n",
        "print(dic_r['tgt'].shape)\n",
        "print(dic_r['mask'].shape)\n",
        "\n",
        "of_input = dic_r['src']\n",
        "of_target = dic_r['src']\n",
        "of_mask = dic_r['mask']\n",
        "\n",
        "\"\"\" End of this part\"\"\"\n",
        "\n",
        "\n",
        "DEVICE = 'cpu' # later replace with 'cuda' for GPU\n",
        "EPOCHS = 3\n",
        "val_step = 50\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "      model.train()\n",
        "      cur_loss = []\n",
        "      cur_acc = []\n",
        "\n",
        "      for batch_idx, dic_r in enumerate(train_data_loader):\n",
        "          batch = dic_r['src'][batch_idx].to(device)\n",
        "          labels = dic_r['tgt'][batch_idx].to(device)\n",
        "          mask = dic_r['mask'][batch_idx].to(device)\n",
        "\n",
        "          #Reset the optimizer \n",
        "          optimizer.zero_grad() \n",
        "          prediction = model(batch)\n",
        "          labels_hat,_ = max(prediction,axis=-1)\n",
        "          accuracy = (labels_hat == labels).mean\n",
        "          cur_acc.append(accuracy)\n",
        "          loss = criterion(prediction, labels)\n",
        "          cur_loss.append(loss.item())\n",
        "          #Backpropagate the error\n",
        "          loss.backward()\n",
        "          #Update the weights based on the error\n",
        "          optimizer.step()\n",
        "\n",
        "      # Validate the model every n-th episonde\n",
        "      if batch_idx+1 % val_step == 0:\n",
        "          \n",
        "          print(f\"Accuracy over last 50 iterations : {sum(cur_loss[:-50-1:-1])/50:.3f}\")\n",
        "          \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur_acc = [2,2,3,4,5]\n",
        "sum(cur_acc[:-3-1:-1])/3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQijTPJa9l7z",
        "outputId": "36ce4823-8aa4-4e21-c953-991f9c0538b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 4, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "cell_id": "2f12827ec5ad4a4ba18ae8d260857cd8",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 62,
        "id": "gDHcjbEDIFRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what's the accuracy is of our model. Since we already implemented accuracy in the previous exercise, we'll now let you use the torchmetrics package."
      ],
      "metadata": {
        "cell_id": "23af9a15c9e84bd3bea4a62c7c7e9459",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 74.78125,
        "id": "EuoCU3gQIFRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [torch.FloatTensor([1]).view(1, -1), torch.FloatTensor([2]).view(1, -1)]\n",
        "torch.stack(a)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "41s8P3pGBthF",
        "outputId": "45ca2334-eabe-4304-f519-f235a211e7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-5d4741b55c99>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataiter_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataiter_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "18891986243d49afa9305716cbd96aa7",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 97,
        "id": "aKWIC-LrIFRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292d4470-6a00-41e1-9264-8e47fe5c0941"
      },
      "source": [
        "from torchmetrics import Accuracy\n",
        "help(Accuracy)\n",
        "accuracy = Accuracy(task=\"multilabel\",num_labels=trg_vocab_size,average='micro')\n",
        "\n",
        "preds_list = []\n",
        "target_list = []\n",
        "dataiter_test = iter(train_data_loader_test)\n",
        "\n",
        "for i in range(n=4):\n",
        "  dic_r_test = next(dataiter_test)\n",
        "  preds_list.append(dic_r_test['src'])\n",
        "  target_list.append(dic_r_test['tgt'])\n",
        "\n",
        "preds = torch.stack(preds_list)\n",
        "target = torch.stack(target_list)\n",
        "\n",
        "accuracy(preds, target)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class Accuracy in module torchmetrics.classification.accuracy:\n",
            "\n",
            "class Accuracy(builtins.object)\n",
            " |  Accuracy(task: Literal['binary', 'multiclass', 'multilabel'], threshold: float = 0.5, num_classes: Optional[int] = None, num_labels: Optional[int] = None, average: Optional[Literal['micro', 'macro', 'weighted', 'none']] = 'micro', multidim_average: Literal['global', 'samplewise'] = 'global', top_k: Optional[int] = 1, ignore_index: Optional[int] = None, validate_args: bool = True, **kwargs: Any) -> torchmetrics.metric.Metric\n",
            " |  \n",
            " |  Computes `Accuracy`_\n",
            " |  \n",
            " |  .. math::\n",
            " |      \\text{Accuracy} = \\frac{1}{N}\\sum_i^N 1(y_i = \\hat{y}_i)\n",
            " |  \n",
            " |  Where :math:`y` is a tensor of target values, and :math:`\\hat{y}` is a tensor of predictions.\n",
            " |  \n",
            " |  This module is a simple wrapper to get the task specific versions of this metric, which is done by setting the\n",
            " |  ``task`` argument to either ``'binary'``, ``'multiclass'`` or ``multilabel``. See the documentation of\n",
            " |  :mod:`BinaryAccuracy`, :mod:`MulticlassAccuracy` and :mod:`MultilabelAccuracy` for the specific details of\n",
            " |  each argument influence and examples.\n",
            " |  \n",
            " |  Legacy Example:\n",
            " |      >>> import torch\n",
            " |      >>> target = torch.tensor([0, 1, 2, 3])\n",
            " |      >>> preds = torch.tensor([0, 2, 1, 3])\n",
            " |      >>> accuracy = Accuracy(task=\"multiclass\", num_classes=4)\n",
            " |      >>> accuracy(preds, target)\n",
            " |      tensor(0.5000)\n",
            " |  \n",
            " |      >>> target = torch.tensor([0, 1, 2])\n",
            " |      >>> preds = torch.tensor([[0.1, 0.9, 0], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3]])\n",
            " |      >>> accuracy = Accuracy(task=\"multiclass\", num_classes=3, top_k=2)\n",
            " |      >>> accuracy(preds, target)\n",
            " |      tensor(0.6667)\n",
            " |  \n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(cls, task: Literal['binary', 'multiclass', 'multilabel'], threshold: float = 0.5, num_classes: Optional[int] = None, num_labels: Optional[int] = None, average: Optional[Literal['micro', 'macro', 'weighted', 'none']] = 'micro', multidim_average: Literal['global', 'samplewise'] = 'global', top_k: Optional[int] = 1, ignore_index: Optional[int] = None, validate_args: bool = True, **kwargs: Any) -> torchmetrics.metric.Metric\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the average accuracy of all examples in the test dataset."
      ],
      "metadata": {
        "cell_id": "1cd5f69a8dcd41f8918bc9946a1b57e3",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "oA2dbZaTIFRS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "f73337d4e25a494e9c1b138823bc1d22",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 61,
        "id": "sUAUQwhFIFRS"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also look at the accuracy **for each class separately**:"
      ],
      "metadata": {
        "cell_id": "d8a4e62ebfb64dc5a6659df362eaeb50",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "mnxiymacIFRT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "98b6c3390d1b42d2bd9b2e91608625aa",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 61,
        "id": "mXUSZI6bIFRT"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Embeddings"
      ],
      "metadata": {
        "formattedRanges": [],
        "cell_id": "c92bfb82034344bb9cd220de8e4e157c",
        "tags": [],
        "is_collapsed": false,
        "deepnote_cell_type": "text-cell-h2",
        "id": "AVNf-urRIFRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The attention mechanism does not consider the position of the tokens which hurts its performance for many problems. We can solve this issue in several ways. We can either add a positional encoding (via trigonometric functions) or we can learn positional embeddings along the way, in a similar way as BERT does. Here, we will add learnable positional embeddings to our exisisting model with another embedding layer."
      ],
      "metadata": {
        "cell_id": "070435ca57a94f1ea6e71050d57619aa",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 119.5625,
        "id": "b6PVSx6dIFRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The longest sequence in our dataset has 78 tokens (you can trust us on that). So, let's set the number of embeddings for our positional embedding layer to that number. Again, you should use `nn.Embedding`."
      ],
      "metadata": {
        "cell_id": "5ff82560d6f24630a9bed80d6b38b7f1",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 74.78125,
        "id": "NK2kz8bSIFRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the inner parts of your `Transformer` class and add positional embeddings to it."
      ],
      "metadata": {
        "cell_id": "0363608d5a9a48f5be6f2e6ddbd7397c",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "U0vXrRlAIFRU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "129e0b2b46c8494c90491fe2d2e137f0",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 313,
        "id": "vRHNqRyNIFRU"
      },
      "source": [
        "\n",
        "class TransformerPos(nn.Module):\n",
        "    \"\"\"\n",
        "    emb_n: number of token embeddings\n",
        "    pos_emb_n: number of position embeddings\n",
        "    hidden_n: hidden dimension\n",
        "    n: number of layers\n",
        "    h: number of heads per layer\n",
        "        \"\"\"\n",
        "    def __init__(     self,\n",
        "                embed_n,\n",
        "                pos_emb_n,\n",
        "                hidden_n,\n",
        "                n,\n",
        "                h,\n",
        "                device,\n",
        "                dropout,\n",
        "                num_targ_vocab\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.pos_emb_n = pos_emb_n\n",
        "        self.device = device\n",
        "        self.embed1 = torch.nn.Embedding(embed_n,hidden_n)\n",
        "        self.embed2 = torch.nn.Embedding(pos_emb_n,hidden_n)   # seq len must be equal or smaller than max len\n",
        "        self.proj = torch.nn.Linear(hidden_n,num_targ_vocab)\n",
        "\n",
        "        self.layers = torch.nn.ModuleList( [ TransformerBlock(hidden_n,h) for i in range( n )] )\n",
        "\n",
        "\n",
        "    def forward(self,input,mask=None):    # input : N L\n",
        "        N,sequence_length = input.shape\n",
        "        positional_encoding = torch.arange(0,self.pos_emb_n).expand(N,self.pos_emb_n).to(self.device)\n",
        "        out = self.embed1(input) + self.embed2(positional_encoding)\n",
        "\n",
        "        #out = self.embed1(input) # N L -> N L D\n",
        "        \n",
        "        for layer in self.layers:\n",
        "          out = layer(out,out,out,mask)\n",
        "        # out = self.proj(out).reshape(N,sequence_length,-1)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(\n",
        "    device\n",
        ")\n",
        "\n",
        "x1 = ((1/3) *torch.linspace(1,2*78,2*78)).reshape(2,-1).to(torch.int32).to(\n",
        "    device\n",
        ")\n",
        "\n",
        "modelPos = TransformerPos(\n",
        "            embed_n= 80,   # dim of word_embeded vector\n",
        "            hidden_n = 256,  # hidden dimension\n",
        "            pos_emb_n = 78,\n",
        "            n=3,       # num of layers\n",
        "            h=2,       # heads\n",
        "            device=\"cpu\",\n",
        "            dropout=0.1,\n",
        "            num_targ_vocab=64) # output vocabs space\n",
        "\n",
        "out = modelPos(x1)\n",
        "out = model(x1)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fclovrYFWYO",
        "outputId": "b1998d79-2c6d-4ef8-f746-38d7527a36da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "torch.Size([2, 78, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "b398b56387f54999966ee9d22a0150b1",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 61,
        "id": "pPslFjtvIFRU"
      },
      "source": [
        "model_pos = CoNLL2000Transformer(TransformerPos(...), ...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "cell_id": "d8f6b79fce144176832210f7a1494288",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 62,
        "id": "W43Zb67DIFRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same procedure as before. Let's reinitialize our optimizer and our loss function and run the same training loop with our new model `model_pos`."
      ],
      "metadata": {
        "cell_id": "507700c451e842c4b9dbdd02857b234d",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 74.78125,
        "id": "Q5k8RZDnIFRV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "7b2c6541371f4e99bb0acfe1212c732d",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 79,
        "id": "MAAjJIdvIFRV"
      },
      "source": [
        "optimizer = ....\n",
        "criterion = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "fac3717095914132b36cbfd70c702715",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 61,
        "id": "PdPBGee8IFRV"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "cell_id": "2dfedd24910c45689ed2a3d4ed804af6",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 62,
        "id": "rUqUvlYPIFRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's check if our performance on the accuracy got improved."
      ],
      "metadata": {
        "cell_id": "472e05fab0d149b8b269a12d8e363b85",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "xUwoKk0pIFRV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "38e0fe847e464f59b1861a749fc43811",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 61,
        "id": "NmJEbRcwIFRW"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, let's also check each class. Which classes got improved the most by adding positional embeddings?"
      ],
      "metadata": {
        "cell_id": "a49fe34010574a0096a020ead994158d",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 52.390625,
        "id": "nP7ktkL2IFRW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "d107d15cf5fe4ee396f6733e093873cc",
        "tags": [],
        "deepnote_cell_type": "code",
        "deepnote_cell_height": 61,
        "id": "aMaI0fSkIFRW"
      },
      "source": [
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last question in this assignment doesn't require you to code anything. Instead, you're asked to point out possible issues with our current approach and name potential improvements. \n",
        "* ...\n",
        "* ...\n",
        "* ..."
      ],
      "metadata": {
        "cell_id": "bfece568a8c1460fafd968adf1972f19",
        "tags": [],
        "deepnote_cell_type": "markdown",
        "deepnote_cell_height": 175.953125,
        "id": "fY1dyqDZIFRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=faa4af3b-d086-4f42-8b7d-d29c91b1d0f6' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ],
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "MwTZbhOMIFRW"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {},
    "deepnote_notebook_id": "df3e6be7-b747-492e-86ed-19bc62a6bb4c",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  }
}